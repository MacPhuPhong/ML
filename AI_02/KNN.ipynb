{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7cae68b",
   "metadata": {},
   "source": [
    "### 🧠 Phân tích và Đánh giá Mô hình K-Nearest Neighbors (KNN)\n",
    "\n",
    "#### 1. Tổng quan lý thuyết KNN\n",
    "K-Nearest Neighbors (KNN) là một thuật toán **học có giám sát (supervised learning)**, thường được sử dụng cho các bài toán **phân loại (classification)** và **hồi quy (regression)**.  \n",
    "Nguyên lý hoạt động rất trực quan: một điểm dữ liệu mới sẽ được gán nhãn dựa trên **các điểm “hàng xóm” gần nhất** trong tập huấn luyện.\n",
    "\n",
    "Khoảng cách giữa các điểm thường được đo bằng các độ đo như:\n",
    "- **Euclidean Distance (khoảng cách Euclid)**\n",
    "- **Manhattan Distance (tổng độ chênh tuyệt đối)**\n",
    "- **Minkowski Distance**  \n",
    "\n",
    "Trong đoạn mã này, khoảng cách **Manhattan** được sử dụng:\n",
    "\\[\n",
    "d(x_1, x_2) = \\sum_{i=1}^{n} |x_{1i} - x_{2i}|\n",
    "\\]\n",
    "\n",
    "Thuật toán sẽ chọn ra **K điểm gần nhất**, sau đó dùng **bỏ phiếu đa số (majority voting)** để xác định nhãn đầu ra.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Cách triển khai trong đoạn mã\n",
    "Đoạn code triển khai KNN **thủ công (from scratch)** để minh họa rõ quy trình hoạt động của thuật toán, bao gồm các bước chính sau:\n",
    "\n",
    "- **Chuẩn bị dữ liệu:**\n",
    "  Dữ liệu được chia thành **5 folder (folder₁ → folder₅)**, dùng cho quá trình **5-fold cross-validation**.  \n",
    "  Mỗi vòng, một folder được chọn làm **test set**, 4 folder còn lại làm **train set**.\n",
    "\n",
    "- **Chuẩn hóa dữ liệu (Normalization):**\n",
    "  Áp dụng phép **Min–Max scaling** đưa các đặc trưng về khoảng [0, 1] để đảm bảo công bằng khi tính khoảng cách.\n",
    "\n",
    "- **Hàm `manhattan_distance`:**\n",
    "  Tính tổng giá trị tuyệt đối giữa từng cặp đặc trưng của hai mẫu dữ liệu.\n",
    "\n",
    "- **Hàm `knn_predict`:**\n",
    "  1. Tính khoảng cách Manhattan giữa mẫu test và toàn bộ mẫu train.  \n",
    "  2. Chọn **k điểm gần nhất**.  \n",
    "  3. Thực hiện **bỏ phiếu đa số** để xác định nhãn dự đoán.\n",
    "\n",
    "- **Đánh giá mô hình:**\n",
    "  Với mỗi fold, chương trình tính **độ chính xác (Accuracy)** bằng công thức:\n",
    "  \\[\n",
    "  \\text{Accuracy} = \\frac{\\text{Số dự đoán đúng}}{\\text{Tổng số mẫu}}\n",
    "  \\]\n",
    "  Kết quả từng fold được lưu trong danh sách `results` và xuất ra file CSV.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Nhận xét và Đánh giá\n",
    "**Ưu điểm:**\n",
    "- Cấu trúc mã rõ ràng, dễ hiểu, minh họa chính xác cơ chế của KNN.  \n",
    "- Việc **không sử dụng thư viện sklearn** giúp thể hiện rõ bản chất thuật toán.  \n",
    "- Sử dụng **cross-validation 5-fold** giúp đánh giá tổng quát độ ổn định mô hình.  \n",
    "- Chuẩn hóa dữ liệu đúng cách giúp tránh sai lệch do thang đo đặc trưng.\n",
    "\n",
    "**Hạn chế:**\n",
    "- Chi phí tính toán cao do phải đo khoảng cách đến toàn bộ mẫu train cho mỗi dự đoán.  \n",
    "- Chưa có cơ chế tối ưu như **KD-Tree** hay **Ball-Tree**.  \n",
    "- Giá trị `k` cố định (k=3) chưa được tinh chỉnh bằng grid search hoặc cross-validation sâu hơn.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Kết luận\n",
    "Mô hình **KNN (k=3, Manhattan distance)** cho kết quả ổn định và phù hợp với bài toán **phân loại Iris**.  \n",
    "Phương pháp **5-fold cross-validation** cung cấp đánh giá khách quan về độ chính xác trung bình.  \n",
    "Đoạn mã là một ví dụ tiêu biểu cho việc **hiểu bản chất thuật toán học máy cơ bản**, tạo nền tảng để tiến tới các mô hình phức tạp hơn như SVM, Decision Tree hay Neural Network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bd30101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Test với folder_1 (k=3) =====\n",
      "Accuracy = 0.967 (29/30 đúng)\n",
      "Đã lưu: /media/pphong/D:/ML & DL/ML/AI_02/result_folder/result_folder_1_k3.csv\n",
      "\n",
      "===== Test với folder_2 (k=3) =====\n",
      "Accuracy = 1.000 (30/30 đúng)\n",
      "Đã lưu: /media/pphong/D:/ML & DL/ML/AI_02/result_folder/result_folder_2_k3.csv\n",
      "\n",
      "===== Test với folder_3 (k=3) =====\n",
      "Accuracy = 0.933 (28/30 đúng)\n",
      "Đã lưu: /media/pphong/D:/ML & DL/ML/AI_02/result_folder/result_folder_3_k3.csv\n",
      "\n",
      "===== Test với folder_4 (k=3) =====\n",
      "Accuracy = 0.967 (29/30 đúng)\n",
      "Đã lưu: /media/pphong/D:/ML & DL/ML/AI_02/result_folder/result_folder_4_k3.csv\n",
      "\n",
      "===== Test với folder_5 (k=3) =====\n",
      "Accuracy = 0.967 (29/30 đúng)\n",
      "Đã lưu: /media/pphong/D:/ML & DL/ML/AI_02/result_folder/result_folder_5_k3.csv\n",
      "\n",
      "=== KẾT QUẢ 5-FOLD CROSS-VALIDATION ===\n",
      "Fold 1: Accuracy = 0.967\n",
      "Fold 2: Accuracy = 1.000\n",
      "Fold 3: Accuracy = 0.933\n",
      "Fold 4: Accuracy = 0.967\n",
      "Fold 5: Accuracy = 0.967\n",
      "Mean accuracy = 0.967\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# === Hàm tính khoảng cách Manhattan ===\n",
    "def manhattan_distance(x1, x2):\n",
    "    return np.sum(np.abs(x1 - x2))\n",
    "\n",
    "# === Hàm dự đoán bằng KNN ===\n",
    "def knn_predict(test_sample, train_features, train_labels, k=3):\n",
    "    # Tính khoảng cách từ test_sample đến tất cả train\n",
    "    distances = [manhattan_distance(test_sample, train_features.iloc[i]) \n",
    "                 for i in range(len(train_features))]\n",
    "    \n",
    "    # Lấy chỉ số của k điểm gần nhất\n",
    "    k_indices = np.argsort(distances)[:k]\n",
    "    k_labels = train_labels.iloc[k_indices]\n",
    "    \n",
    "    # Bỏ phiếu đa số\n",
    "    most_common = Counter(k_labels).most_common(1)[0][0]\n",
    "    return most_common\n",
    "\n",
    "# === Thư mục dữ liệu và kết quả ===\n",
    "base_dir = \"/media/pphong/D:/ML & DL/ML/AI_02/iris_folder\"\n",
    "result_dir = \"/media/pphong/D:/ML & DL/ML/AI_02/result_folder\"\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# === Danh sách folder ===\n",
    "folders = [f\"folder_{i}\" for i in range(1, 6)]\n",
    "results = []   # Lưu accuracy từng lần\n",
    "k = 3          # Số láng giềng gần nhất\n",
    "\n",
    "# === Cross-validation 5-fold ===\n",
    "for test_folder in folders:\n",
    "    print(f\"\\n===== Test với {test_folder} (k={k}) =====\")\n",
    "\n",
    "    # Test data\n",
    "    test_path = os.path.join(base_dir, test_folder)\n",
    "    test_csv = [f for f in os.listdir(test_path) if f.endswith('.csv')]\n",
    "    if not test_csv:\n",
    "        raise FileNotFoundError(f\"Không tìm thấy file CSV trong {test_path}\")\n",
    "    test_df = pd.read_csv(os.path.join(test_path, test_csv[0]))\n",
    "\n",
    "    # Train data (4 folder còn lại)\n",
    "    train_folders = [f for f in folders if f != test_folder]\n",
    "    train_dfs = []\n",
    "    for f in train_folders:\n",
    "        csvs = [c for c in os.listdir(os.path.join(base_dir, f)) if c.endswith('.csv')]\n",
    "        if not csvs:\n",
    "            raise FileNotFoundError(f\"Không tìm thấy CSV trong {f}\")\n",
    "        train_dfs.append(pd.read_csv(os.path.join(base_dir, f, csvs[0])))\n",
    "    train_df = pd.concat(train_dfs, ignore_index=True)\n",
    "\n",
    "    # === Chuẩn hóa dữ liệu (0–1) theo train ===\n",
    "    X_train = train_df.drop(columns=['Id', 'Species'])\n",
    "    y_train = train_df['Species']\n",
    "    X_test = test_df.drop(columns=['Id', 'Species'])\n",
    "    y_test = test_df['Species']\n",
    "\n",
    "    X_train_norm = (X_train - X_train.min()) / (X_train.max() - X_train.min())\n",
    "    X_test_norm = (X_test - X_train.min()) / (X_train.max() - X_train.min())\n",
    "\n",
    "    # === Dự đoán ===\n",
    "    predictions = [knn_predict(X_test_norm.iloc[i], X_train_norm, y_train, k=k) \n",
    "                   for i in range(len(X_test_norm))]\n",
    "\n",
    "    # === Tính accuracy ===\n",
    "    correct = sum(1 for i in range(len(y_test)) if predictions[i] == y_test.iloc[i])\n",
    "    total = len(y_test)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    results.append(accuracy)\n",
    "    print(f\"Accuracy = {accuracy:.3f} ({correct}/{total} đúng)\")\n",
    "\n",
    "    # Lưu kết quả\n",
    "    result_df = test_df.copy()\n",
    "    result_df['Predicted'] = predictions\n",
    "    result_path = os.path.join(result_dir, f\"result_{test_folder}_k{k}.csv\")\n",
    "    result_df.to_csv(result_path, index=False)\n",
    "    print(f\"Đã lưu: {result_path}\")\n",
    "\n",
    "# === Tổng kết ===\n",
    "print(\"\\n=== KẾT QUẢ 5-FOLD CROSS-VALIDATION ===\")\n",
    "for i, acc in enumerate(results, 1):\n",
    "    print(f\"Fold {i}: Accuracy = {acc:.3f}\")\n",
    "print(f\"Mean accuracy = {np.mean(results):.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
